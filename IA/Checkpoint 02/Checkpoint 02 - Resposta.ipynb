{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1UoYAnOMyfw-1hIFbBhL35njv19geQsqy","timestamp":1678222625127},{"file_id":"1hkv89SN4bNo8Ju-ich_bbidpYIIFLInN","timestamp":1677084622610},{"file_id":"1d2KGCuy-3rNVRNkiGwLlUK3PpNBHYVd9","timestamp":1677084350447},{"file_id":"https://github.com/toyusan/aula-fiap-disruptive-archs/blob/main/Checkpoint%2001/Checkpoint%2001.ipynb","timestamp":1677082691922},{"file_id":"14YozB2LgJjiX6mINy1BvCX7UYRy4380L","timestamp":1677033787677}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Checkpoint 02 - Redes Neurais**\n","\n","## **Objetivo**\n","Avaliar conceitos sobre Redes Neurais adquiridos no curso.\n","\n","## **Descrição do Desafio**\n","Você foi contratado por uma empresa de tecnologia que está desenvolvendo um aplicativo de reconhecimento de objetos em imagens. Eles querem que você crie um modelo de rede neural convolucional capaz de classificar imagens do conjunto de dados CIFAR-10. O aplicativo será usado para ajudar os usuários a identificar objetos em tempo real.\n","\n","Sua tarefa é criar um modelo de CNN que possa classificar as imagens do CIFAR-10 com o máximo de precisão que conseguir. A empresa recomenda usar como framework de aprendizado profundo o TensorFlow e Keras. Além disso, eles pedem que você realize transferência de aprendizado para melhorar a precisão do modelo. Para isso, você deve usar um modelo pré-treinado, como o VGG16, como ponto de partida e ajustá-lo para a tarefa de classificação do CIFAR-10.\n","\n","Para facilitar o seu trabalho, a empresa disponibilizou um roteiro que deve ser seguido para que o seu projeto esteja dentro dos padrões seguidos pelo time de desenvolvimento.\n","\n","Ao final do projeto, você deve enviar seu modelo treinado e um relatório em vídeo explicando como ele foi construído e avaliado. A empresa irá avaliar seu trabalho com base na precisão do modelo e na qualidade do relatório apresentado. Boa sorte!"],"metadata":{"id":"j-bzGvV3uE1y"}},{"cell_type":"markdown","source":["## **Critério de avaliação**\n","> Cada item do roteiro abaixo vale 1 ponto, totalizando 9 pontos;\n","\n","> O relatório em video vale 1 ponto;\n","\n","A entrega dos itens do roteiro e do video totalizam 10 pontos."],"metadata":{"id":"00pF_1rGQj_I"}},{"cell_type":"markdown","source":["### **Roteiro de Desenvolvimento**"],"metadata":{"id":"CN8hG9ZpRCys"}},{"cell_type":"markdown","source":["1 - Carregue o conjunto de dados CIFAR-10 que é disponibilizado pelo Keras."],"metadata":{"id":"3sD4e4IY13Ux"}},{"cell_type":"code","source":["#Sua resposta aqui\n","\n","# Importar as bibliotecas necessárias\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","from keras.datasets import cifar10\n","\n","# Bibliotecas para o Transfer Learning\n","from keras.models import Model\n","from keras.applications import VGG16\n","from keras.applications import VGG19\n","from keras.applications import DenseNet121\n","\n","# Definir as configurações do modelo\n","batch_size = 128\n","num_classes = 10\n","epochs = 50"],"metadata":{"id":"SsuvPzQQ5PAt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2 - Divida o conjunto de dados em conjuntos de treinamento, validação e teste."],"metadata":{"id":"JkvVJsjg5kTq"}},{"cell_type":"code","source":["#Sua resposta aqui\n","# Carregar o conjunto de dados CIFAR-10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","# Mostra as caracteristicas do dataset\n","print(x_train.shape)\n","print(np.unique(y_train))\n","\n","print(x_test.shape)\n","print(np.unique(y_test))"],"metadata":{"id":"ENdW7hn56FFp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682452690973,"user_tz":180,"elapsed":1345,"user":{"displayName":"Airton Toyofuku","userId":"04040407237829874775"}},"outputId":"693f681e-b1f6-46f3-bf52-4e74de6bc030"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(50000, 32, 32, 3)\n","[0 1 2 3 4 5 6 7 8 9]\n","(10000, 32, 32, 3)\n","[0 1 2 3 4 5 6 7 8 9]\n"]}]},{"cell_type":"markdown","source":["3 - Pré-processamento de dados:\n","\n","> Redimensione as imagens para um tamanho adequado (por exemplo, 32x32 pixels).\n","\n","> Normalize as imagens para que os valores dos pixels fiquem entre 0 e 1."],"metadata":{"id":"qXaP-3r05bSZ"}},{"cell_type":"code","source":["#Sua resposta aqui\n","x_train = x_train.astype(\"float32\") / 255\n","x_test = x_test.astype(\"float32\") / 255\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"metadata":{"id":"FqWaPS5d7yk0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4 - Crie uma arquitetura de CNN:\n",">Defina o número de camadas convolucionais e totalmente conectadas.\n","\n",">Defina a função de ativação para cada camada.\n","\n",">Adicione camadas de regularização, como dropout ou batch normalization."],"metadata":{"id":"O_m8RaIs6KIz"}},{"cell_type":"code","source":["#Sua resposta aqui\n","model = keras.Sequential(\n","    [\n","        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n","        layers.MaxPooling2D(pool_size=(2, 2)),\n","        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n","        layers.MaxPooling2D(pool_size=(2, 2)),\n","        layers.Flatten(),\n","        layers.Dropout(0.5),\n","        layers.Dense(num_classes, activation=\"softmax\"),\n","    ]\n",")"],"metadata":{"id":"TRs56I5DOq6l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5 - Compile o modelo:\n",">Defina a função de perda;\n","\n",">Escolha um otimizador;\n","\n",">Escolha uma métrica de avaliação;"],"metadata":{"id":"uUkBz0pu6nLk"}},{"cell_type":"code","source":["#Sua resposta aqui\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"],"metadata":{"id":"HJWeZhwSO317"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6 - Treine o modelo:\n","> Ajuste os hiperparâmetros, como a taxa de aprendizado e o tamanho do lote.\n","\n","> Use o conjunto de treinamento para treinar o modelo e o conjunto de validação para avaliar o desempenho do modelo durante o treinamento.\n","\n","> Ajuste o modelo conforme necessário com base na performance no conjunto de validação."],"metadata":{"id":"H9gsbQvj6y_m"}},{"cell_type":"code","source":["#Sua resposta aqui\n","history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"],"metadata":{"id":"WW17xlyN78B8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7 - Avalie o modelo usando o conjunto de testes."],"metadata":{"id":"QpDpVyWw7-Au"}},{"cell_type":"code","source":["#Sua resposta aqui\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"],"metadata":{"id":"vf4QB14J8Usb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8 - Use transfer learning para tentar melhorar o seu modelo:\n","\n","> Carregue um modelo pré-treinado em um conjunto de dados semelhante ao CIFAR-10, como o ImageNet.\n","\n","> Congele as camadas convolucionais do modelo pré-treinado e adicione novas camadas totalmente conectadas no topo.\n","\n","> Treine apenas as novas camadas totalmente conectadas no conjunto de dados CIFAR-10."],"metadata":{"id":"YpNVMhSw9Fe7"}},{"cell_type":"code","source":["# Essa funçao de processamento é necessaria para o modelo Densenet\n","def preprocess_data(X, Y):\n","    \"\"\"\n","    Pre-processes the data for the model\n","\n","        :param X: numpy.ndarray of shape (m, 32, 32, 3)\n","            containing the CIFAR 10 data, where m is the\n","            number of data points\n","\n","        :param Y: numpy.ndarray of shape (m,) containing\n","            the CIFAR 10 labels for X\n","\n","        :returns: X_p, Y_p\n","    \"\"\"\n","    X_p = keras.applications.densenet.preprocess_input(X)\n","\n","    # encode to one-hot\n","    Y_p = keras.utils.to_categorical(Y, 10)\n","    return X_p, Y_p\n","\n","# pre-procces data\n","x_train, y_train = preprocess_data(x_train, y_train)\n","x_test, y_test = preprocess_data(x_test, y_test)"],"metadata":{"id":"4M1XfmOZzB6R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# input tensor\n","inputs = keras.Input(shape=(32, 32, 3))\n","#upscale = tf.keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x, 224, 224, method=tf.image.ResizeMethod.BILINEAR))(inputs)\n","upscale = tf.keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x, 160, 160, method=tf.image.ResizeMethod.BILINEAR))(inputs)"],"metadata":{"id":"LUpBWT661dpx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Sua resposta aqui\n","\n","\n","#base_model = VGG16(include_top=False, weights=\"imagenet\", input_tensor=upscale, input_shape=(224, 224, 3), pooling = 'max')\n","#base_model = VGG19(include_top=False, weights=\"imagenet\", input_tensor=upscale, input_shape=(160, 160, 3), pooling = 'max')\n","base_model = DenseNet121(include_top=False, weights=\"imagenet\",input_tensor=upscale, input_shape=(160, 160, 3), pooling = 'max')\n","\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","x = layers.Flatten()(base_model.output)\n","x = layers.BatchNormalization()(x)\n","x = layers.Dense(256, activation=\"relu\")(x)\n","x = layers.Dropout(0.3)(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dropout(0.3)(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Dense(64, activation=\"relu\")(x)\n","x = layers.Dropout(0.3)(x)\n","x = layers.Dense(num_classes, activation=\"softmax\")(x)\n","\n","model = Model(inputs=base_model.input, outputs=x)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","#model.summary();"],"metadata":{"id":"zCssWHNU9R8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(x_train, y_train, batch_size=128, epochs=25, validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_Uy94Y3UF8X","executionInfo":{"status":"ok","timestamp":1682455140916,"user_tz":180,"elapsed":2432499,"user":{"displayName":"Airton Toyofuku","userId":"04040407237829874775"}},"outputId":"e07dcb1d-46b0-4506-894a-76724c6ec98c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","391/391 [==============================] - 122s 252ms/step - loss: 0.6715 - accuracy: 0.7833 - val_loss: 0.3544 - val_accuracy: 0.8814\n","Epoch 2/25\n","391/391 [==============================] - 91s 232ms/step - loss: 0.4061 - accuracy: 0.8703 - val_loss: 0.3156 - val_accuracy: 0.8940\n","Epoch 3/25\n","391/391 [==============================] - 97s 247ms/step - loss: 0.3497 - accuracy: 0.8877 - val_loss: 0.3049 - val_accuracy: 0.8986\n","Epoch 4/25\n","391/391 [==============================] - 97s 248ms/step - loss: 0.3124 - accuracy: 0.8989 - val_loss: 0.3008 - val_accuracy: 0.8989\n","Epoch 5/25\n","391/391 [==============================] - 91s 233ms/step - loss: 0.2853 - accuracy: 0.9078 - val_loss: 0.3013 - val_accuracy: 0.9026\n","Epoch 6/25\n","391/391 [==============================] - 97s 248ms/step - loss: 0.2611 - accuracy: 0.9151 - val_loss: 0.3032 - val_accuracy: 0.9012\n","Epoch 7/25\n","391/391 [==============================] - 97s 248ms/step - loss: 0.2352 - accuracy: 0.9242 - val_loss: 0.3083 - val_accuracy: 0.9034\n","Epoch 8/25\n","391/391 [==============================] - 97s 248ms/step - loss: 0.2146 - accuracy: 0.9284 - val_loss: 0.3167 - val_accuracy: 0.9002\n","Epoch 9/25\n","391/391 [==============================] - 97s 248ms/step - loss: 0.1972 - accuracy: 0.9354 - val_loss: 0.3105 - val_accuracy: 0.9022\n","Epoch 10/25\n","391/391 [==============================] - 91s 232ms/step - loss: 0.1867 - accuracy: 0.9377 - val_loss: 0.3190 - val_accuracy: 0.9012\n","Epoch 11/25\n","391/391 [==============================] - 97s 247ms/step - loss: 0.1705 - accuracy: 0.9434 - val_loss: 0.3284 - val_accuracy: 0.8991\n","Epoch 12/25\n","391/391 [==============================] - 97s 248ms/step - loss: 0.1573 - accuracy: 0.9484 - val_loss: 0.3412 - val_accuracy: 0.8998\n","Epoch 13/25\n","391/391 [==============================] - 97s 248ms/step - loss: 0.1488 - accuracy: 0.9518 - val_loss: 0.3376 - val_accuracy: 0.9027\n","Epoch 14/25\n","391/391 [==============================] - 91s 233ms/step - loss: 0.1372 - accuracy: 0.9549 - val_loss: 0.3510 - val_accuracy: 0.8991\n","Epoch 15/25\n","391/391 [==============================] - 97s 247ms/step - loss: 0.1292 - accuracy: 0.9572 - val_loss: 0.3561 - val_accuracy: 0.9012\n","Epoch 16/25\n","391/391 [==============================] - 97s 247ms/step - loss: 0.1239 - accuracy: 0.9580 - val_loss: 0.3683 - val_accuracy: 0.9019\n","Epoch 17/25\n","391/391 [==============================] - 91s 233ms/step - loss: 0.1186 - accuracy: 0.9613 - val_loss: 0.3728 - val_accuracy: 0.8974\n","Epoch 18/25\n","391/391 [==============================] - 97s 247ms/step - loss: 0.1132 - accuracy: 0.9624 - val_loss: 0.3841 - val_accuracy: 0.9000\n","Epoch 19/25\n","391/391 [==============================] - 97s 248ms/step - loss: 0.1096 - accuracy: 0.9634 - val_loss: 0.3929 - val_accuracy: 0.8968\n","Epoch 20/25\n","391/391 [==============================] - 91s 233ms/step - loss: 0.0995 - accuracy: 0.9666 - val_loss: 0.3820 - val_accuracy: 0.9015\n","Epoch 21/25\n","391/391 [==============================] - 97s 247ms/step - loss: 0.0963 - accuracy: 0.9677 - val_loss: 0.3903 - val_accuracy: 0.9011\n","Epoch 22/25\n","391/391 [==============================] - 91s 233ms/step - loss: 0.0935 - accuracy: 0.9694 - val_loss: 0.3980 - val_accuracy: 0.8987\n","Epoch 23/25\n","391/391 [==============================] - 91s 233ms/step - loss: 0.0885 - accuracy: 0.9709 - val_loss: 0.4020 - val_accuracy: 0.9010\n","Epoch 24/25\n","391/391 [==============================] - 96s 247ms/step - loss: 0.0909 - accuracy: 0.9702 - val_loss: 0.3912 - val_accuracy: 0.9027\n","Epoch 25/25\n","391/391 [==============================] - 97s 248ms/step - loss: 0.0841 - accuracy: 0.9717 - val_loss: 0.4147 - val_accuracy: 0.8990\n"]}]},{"cell_type":"markdown","source":["9 - Avalie o modelo transferido usando o conjunto de testes."],"metadata":{"id":"vX3UXMuuQY_V"}},{"cell_type":"code","source":["#Sua resposta aqui\n","# Avaliar o modelo transferido\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print(\"Test loss:\", score[0])\n","print(\"Test accuracy:\", score[1])"],"metadata":{"id":"kb97Kek_Qguu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682455649933,"user_tz":180,"elapsed":21133,"user":{"displayName":"Airton Toyofuku","userId":"04040407237829874775"}},"outputId":"46d0f58e-4dcf-407d-a491-4a457089fcba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.41469669342041016\n","Test accuracy: 0.8989999890327454\n"]}]},{"cell_type":"markdown","source":["10 - Coloque aqui o link para o seu video explicativo"],"metadata":{"id":"wMTcIdJv5NlC"}},{"cell_type":"markdown","source":["Sua resposta aqui:"],"metadata":{"id":"Pkg4LUUf5Syi"}}]}