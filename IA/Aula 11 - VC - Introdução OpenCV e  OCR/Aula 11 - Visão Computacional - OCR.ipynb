{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["rVQrEDcIlhYn","gHTQBzhOlpvP"],"authorship_tag":"ABX9TyPtxdPQiTUo2M2SO0JeGP6S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Aplicando OCR - Usando EasyOCR**"],"metadata":{"id":"5ec7Zlu9eftU"}},{"cell_type":"markdown","source":["## Iniciando com EasyOCR\n","\n","READ the Documentation: https://www.jaided.ai/easyocr/documentation/"],"metadata":{"id":"g7J4FgcilbNi"}},{"cell_type":"markdown","source":["Instale a biblioteca EasyOCR no seu ambiente Python:"],"metadata":{"id":"K8j2DMN9ebRW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgNSdq70cw5X"},"outputs":[],"source":["!pip install easyocr"]},{"cell_type":"markdown","source":["Importe a biblioteca EasyOCR e OpenCV. Também importe outras bibliotecas que você achar necessário"],"metadata":{"id":"1COLV5YaerYn"}},{"cell_type":"code","source":["import easyocr\n","import cv2\n","import matplotlib.pyplot as plt\n","from google.colab.patches import cv2_imshow "],"metadata":{"id":"3yLaNS1we41S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Carregue a imagem que você deseja reconhecer o texto usando openCV e execute a função readtext() da biblioteca EasyOCR:"],"metadata":{"id":"9cLx3lsjfCAZ"}},{"cell_type":"code","source":["# Carrega a imagem utilizando o OpenCV\n","imagem = cv2.imread('/content/geralt.jpg')\n","cv2_imshow(imagem)"],"metadata":{"id":"jJ-CbwdUfDcu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Agora instancie um objeto da classe Reader. Esse objeto será o responsável por identificar os textos na imagem"],"metadata":{"id":"yZr2qgu_gyrb"}},{"cell_type":"code","source":["# Criando o Reader para o idioma Inglês (english) e dizendo para usar GPU\n","reader = easyocr.Reader(lang_list=['en'], gpu = True)"],"metadata":{"id":"gNPG6MuGgydv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Carregue a imagem que você deseja reconhecer o texto e execute a função readtext() da biblioteca EasyOCR:"],"metadata":{"id":"lCzRzztJhzRG"}},{"cell_type":"code","source":["texto = reader.readtext(image = imagem, detail = 0)\n"],"metadata":{"id":"i4liJLjnh5ha"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["O resultado é uma lista com cada linha \"lida\" da imagem"],"metadata":{"id":"aupo7l6TfIW6"}},{"cell_type":"code","source":["texto"],"metadata":{"id":"f1edrjBCfLb_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Percebe-se que o resultado é até bom, mas temos alguns erros, como por exemplo:\n","\n","* No treho \"Lesser, greater, middling...\", ele subistitui a reticências por hifen;\n","\n","* No trecho \"If I'm to choose...\", ele substituiu o I' por T;\n","\n","* O mesmo ocorre na ultima linha, com \"I'd rather...\". \n","\n","Vamos ignorar esses erros por enquanto..."],"metadata":{"id":"rw5P9XGFixP9"}},{"cell_type":"markdown","source":["## Lendo Textos Completos"],"metadata":{"id":"rVQrEDcIlhYn"}},{"cell_type":"markdown","source":[" Agora vamos usar uma outra imagem de um texto mais estruturado"],"metadata":{"id":"IVhfQiV5j6Xz"}},{"cell_type":"code","source":["imagem2 = cv2.imread('/content/dissertacao.JPG')\n","cv2_imshow(imagem2)"],"metadata":{"id":"YMsbU5KXkpgy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["texto = reader.readtext(image = imagem2, detail = 0)\n","texto"],"metadata":{"id":"Fp70M5zJj6lT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Neste caso, cada linha foi colocada num item da lista. Para que o texto seja lido como um paragrafo, precisamos usar outro parametro, o paragraph!"],"metadata":{"id":"CoD1Km9UlI9l"}},{"cell_type":"code","source":["texto = reader.readtext(image = imagem2, detail = 0, paragraph = True)\n","texto"],"metadata":{"id":"jgowEeeTk7WR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Identificando a posição do texto na imagem"],"metadata":{"id":"gHTQBzhOlpvP"}},{"cell_type":"code","source":["imagem3 = cv2.imread('/content/avenida.JPG')\n","cv2_imshow(imagem3)"],"metadata":{"id":"YrP9Mdvgm22n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Usando o Reader do EeasyOCR, temos mais informações além do texto em si. O Reader nos retorna também uma lista de tuplas, em que além do texto, ele também nos informa em que parte da imagem ele identificou aquele texto e qual o grau de confiança que ele tem."],"metadata":{"id":"VGgnXM3NnbLn"}},{"cell_type":"code","source":["resultado = reader.readtext(image = imagem3)\n","resultado"],"metadata":{"id":"yBt4UEcmnGxC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Com essas informações, podemos desenhar um retangulo ao redor das palavras detectadas. Para isso, precisamos das coordenadas de cada vertice do retangulo para usarmos o método cv2.retangle, que precisa dos seguintes parametros:\n","\n","* imagem onde será desenhado o retangulo;\n","\n","* ponto do vertice superior esquerdo;\n","\n","* ponto do vertice inferior direito;\n","\n","* cor do retangulo no formato BGR;\n","\n","* espessura da linha do retangulo;"],"metadata":{"id":"omnQrIQnogEd"}},{"cell_type":"code","source":["for(coordenadas, texto, probabilidade) in resultado:\n","  if(probabilidade >= 0.5):\n","    (sup_esq, sup_dir, inf_dir, inf_esq) = coordenadas\n","    sup_esq = (int(sup_esq[0]),int(sup_esq[1]))\n","    sup_dir = (int(sup_dir[0]),int(sup_dir[1]))\n","    inf_dir = (int(inf_dir[0]),int(inf_dir[1]))\n","    inf_esq = (int(inf_esq[0]),int(inf_esq[1]))\n","    cv2.rectangle(imagem3,sup_esq, inf_dir,(255,0,0),2)\n","cv2_imshow(imagem3)"],"metadata":{"id":"BEnAHkJjoktq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imagem4 = cv2.imread('/content/avenida2.JPG')\n","resultado = reader.readtext(image = imagem4)\n","for(coordenadas, texto, probabilidade) in resultado:\n","  if(probabilidade >= 0.3):\n","    (sup_esq, sup_dir, inf_dir, inf_esq) = coordenadas\n","    sup_esq = (int(sup_esq[0]),int(sup_esq[1]))\n","    sup_dir = (int(sup_dir[0]),int(sup_dir[1]))\n","    inf_dir = (int(inf_dir[0]),int(inf_dir[1]))\n","    inf_esq = (int(inf_esq[0]),int(inf_esq[1]))\n","    cv2.rectangle(imagem4,sup_esq, inf_dir,(255,0,0),2)\n","cv2_imshow(imagem4)"],"metadata":{"id":"PX5nAn5XrFiE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultado"],"metadata":{"id":"3_MMle13rrR6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Aplicações de OCR"],"metadata":{"id":"rlXk8gi2tRle"}},{"cell_type":"markdown","source":["Vamos agora fazer algumas aplicações básicas:"],"metadata":{"id":"5-_eG7MdtUgH"}},{"cell_type":"markdown","source":["1 - Integrar o OCR com uma biblioteca Text to Speech para gerar um audio book, para isso, precisamos instalar a biblioteca gtts (Google Text To Speech) e a biblioteca mpg321, para salvar o arquivo mp3"],"metadata":{"id":"8W3P1LP6tyHh"}},{"cell_type":"code","source":["!pip install gtts\n","!apt-get install -y mpg321"],"metadata":{"id":"yxcgWRjCte4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gtts import gTTS\n","\n","# Carregando a imagem e criando o texto via OCR\n","imagem = cv2.imread('/content/geralt.jpg')\n","reader = easyocr.Reader(lang_list=['en'], gpu = True)\n","texto = ' '.join(reader.readtext(image = imagem, detail = 0))\n","\n","# Cria um objeto gTTS com o texto reconhecido\n","tts = gTTS(text=texto, lang='en')\n","\n","# Salva o arquivo de áudio em disco\n","tts.save('GeraldQuote.mp3')"],"metadata":{"id":"ixIr_PFYtw5R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["agora com um texto completo"],"metadata":{"id":"PXraqhD8vt94"}},{"cell_type":"code","source":["# Carregando a imagem e criando o texto via OCR\n","imagem = cv2.imread('/content/dissertacao.JPG')\n","reader = easyocr.Reader(lang_list=['en'], gpu = True)\n","texto = ' '.join(reader.readtext(image = imagem, detail = 0))\n","\n","# Cria um objeto gTTS com o texto reconhecido\n","tts = gTTS(text=texto, lang='en')\n","\n","# Salva o arquivo de áudio em disco\n","tts.save('Dissertacao.mp3')"],"metadata":{"id":"7ehMFhPZvvvX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2 - Um tradutor que pode ser usado apenas apontando a camera para uma palavra"],"metadata":{"id":"JA5mq5rwx1tt"}},{"cell_type":"code","source":["!pip install googletrans==4.0.0rc1"],"metadata":{"id":"f5Sd5FN510PZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","import easyocr\n","import cv2\n","from googletrans import Translator\n","\n","# Carregando a imagem e criando o texto via OCR\n","imagem = cv2.imread('/content/geralt.jpg')\n","reader = easyocr.Reader(lang_list=['en'], gpu = True)\n","texto = ' '.join(reader.readtext(image = imagem, detail = 0))\n","\n","# Inicializa o tradutor\n","translator = Translator()\n","\n","# Traduz a palavra para o inglês\n","texto_en = translator.translate(texto, dest='pt').text\n","\n","print(texto_en)"],"metadata":{"id":"GSVgMKWFyA54"},"execution_count":null,"outputs":[]}]}